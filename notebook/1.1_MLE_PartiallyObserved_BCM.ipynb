{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6855a71",
   "metadata": {},
   "source": [
    "# ML Estimation Partial Observed Bounded Confidence Model\n",
    "In this notebook we estimate the parameter $\\epsilon$ in a BC model with full observations on the opinions and partial observations on the edges.\n",
    "\n",
    "The likelihood to be optimized is \n",
    "\n",
    "$\\mathcal{L}(\\epsilon) = \\sum\\limits_{j: s_j = 1} \\log \\kappa_{\\epsilon}(\\hat{e}_j) + \\sum\\limits_{j: s_j = 0} \\log \\sum\\limits_{e \\in V^2} (1 - \\kappa_{\\epsilon}(e)) P(e)$\n",
    "\n",
    "where $\\kappa = \\sigma(\\rho \\cdot (\\epsilon - | \\Delta X |))$ is the probability of having a positive interaction, and $s = 1$ if the interaction is positive, and $s = 0$ otherwise.\n",
    "$e$ are the edges (latent), and $\\hat{e} = e$ if the edges are observed ($s = 1$) and $\\hat{e} = \\emptyset$ if the edges are hidden ($s = 0$).\n",
    "\n",
    "We maximise $\\mathcal{L}$ with gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4532853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter \n",
    "\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "from simulator_opinion_dynamics import kappa_from_epsilon\n",
    "import simulator_opinion_dynamics as sod\n",
    "from initialize_model import EarlyStopping,RandomizeEpsilon,choose_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78914ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC_Observe_positive_Estimation(nn.Module):\n",
    "    \n",
    "    def __init__(self, parameters0, X, edges, sample_pairs = 50):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # epsilon0 is the initialization of epsilon\n",
    "        epsilon0, rho = parameters0\n",
    "        self.rho = rho\n",
    "        uvst = sod.convert_edges_uvst(edges)\n",
    "        u,v,s,t = uvst[:, uvst[2,:] == 1]\n",
    "        self.X = X\n",
    "        # store the matrix of the differences of X and update it at each time\n",
    "        self.diff_X = X[t,u] - X[t,v]\n",
    "        # optimize theta, that is the logit of 2 * epsilon (this is useful to bound epsilon in [0, 0.5])\n",
    "        theta = torch.tensor([logit(2 * epsilon0)], requires_grad = True)\n",
    "        self.theta = nn.Parameter(theta)\n",
    "        \n",
    "        _, self.edge_per_t, _ = edges.size()\n",
    "        self.T, self.N = X.size()\n",
    "        # we compute the sample mean of having a negative interaction\n",
    "        # sample_pairs is the number of pairs sampled at each time to compute the mean\n",
    "        self.sample_pairs = sample_pairs\n",
    "        self.n_negative_interactions = self.edge_per_t - edges.sum(axis = 1)[:,2]\n",
    "        \n",
    "    def forward(self):\n",
    "        epsilon = torch.sigmoid(self.theta) / 2\n",
    "        # probability of having the observed positive interactions\n",
    "        kappa_pos = kappa_from_epsilon(epsilon, self.diff_X, self.rho)\n",
    "        #sample sample_pairs pairs of nodes and put them into a tensor\n",
    "        u_sample, v_sample = torch.tensor((np.random.rand((self.T - 1) * self.sample_pairs, self.N).argpartition(2,axis = 1)[:,:2]).T)\n",
    "        u_sample, v_sample = u_sample.reshape(self.sample_pairs, self.T-1), v_sample.reshape(self.sample_pairs, self.T-1)\n",
    "        diff_sample_X = (torch.gather(self.X, 1, u_sample.T) - torch.gather(self.X, 1, v_sample.T))\n",
    "        #probability of having one negative interaction (as sample mean of sample pairs)\n",
    "        kappa_neg = 1 - (kappa_from_epsilon(epsilon, diff_sample_X, self.rho)).mean(axis = 1)\n",
    "\n",
    "        return kappa_pos, kappa_neg\n",
    "    \n",
    "    def neg_log_likelihood_function(kappa_pos, kappa_neg, n_negative_interactions, t_minibatch, t_pos_minibatch):\n",
    "        log_likelihood_observed = torch.sum(torch.log(kappa_pos))\n",
    "        log_likelihood_non_observed = torch.sum(torch.log(kappa_neg) * n_negative_interactions)\n",
    "        \n",
    "        neg_tot_log_likelihood = - log_likelihood_observed - log_likelihood_non_observed\n",
    "        \n",
    "        return neg_tot_log_likelihood\n",
    "\n",
    "    def neg_log_likelihood_function_minibatch(kappa_pos, kappa_neg, n_negative_interactions, t_minibatch, t_pos_minibatch):\n",
    "        log_likelihood_observed = torch.sum(torch.log(kappa_pos)[t_pos_minibatch])\n",
    "        log_likelihood_non_observed = torch.sum((torch.log(kappa_neg) * n_negative_interactions)[t_minibatch])\n",
    "        \n",
    "        neg_tot_log_likelihood = - log_likelihood_observed - log_likelihood_non_observed\n",
    "        \n",
    "        return neg_tot_log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e2ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used for accessing the positive interactions at each time\n",
    "# when having a list of only the positive interactions\n",
    "def list_of_t_indices(t, T):\n",
    "    l_indices = [[] for u in np.arange(T - 1)]\n",
    "    for ind in np.arange(len(t)):\n",
    "        l_indices[t[ind].item()].append(ind)\n",
    "    return l_indices\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb3e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_BC_observe_positive(X, edges, rho, num_epochs, sample_pairs = 50,\n",
    "                                         epsilon0 = 0.25, optimizer_name = \"adam\",\n",
    "                                         lr = 0.05, hide_progress = True, minibatch_size = 0, seed = None,\n",
    "                                         early_stopping_kw = {\"patience\": 20, \"min_delta\": 1e-5, \"min_epochs\": 20, \"long_run_delta\": 1e-5, \"long_run_diff\":10, \"long_run_patience\": 5}\n",
    "                                        ):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    u,v,s,t = uvst = sod.convert_edges_uvst(edges)\n",
    "    \n",
    "    model_class = BC_Observe_positive_Estimation\n",
    "    model = model_class((epsilon0, rho), X, edges)\n",
    "    if minibatch_size == 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function\n",
    "    if minibatch_size > 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function_minibatch\n",
    "    \n",
    "    T,N = X.shape\n",
    "    \n",
    "    t_pos = uvst[3, uvst[2,:] == 1]\n",
    "    # indices of the positive interactions, for each time\n",
    "    indices_t = list_of_t_indices(t_pos, T)\n",
    "    \n",
    "    early_stopping = EarlyStopping(**early_stopping_kw)\n",
    "    optimizer = choose_optimizer(optimizer_name, lr, model)\n",
    "    \n",
    "    history = {\"epsilon\": [epsilon0], \"loss\": []}\n",
    "    t_minibatch, t_pos_minibatch = None, None\n",
    "    t0 = time()\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), disable = hide_progress):\n",
    "        \n",
    "        if minibatch_size > 0:\n",
    "            t_minibatch = torch.randperm(T-1)[:minibatch_size]\n",
    "            t_pos_minibatch = sum(list(itemgetter(*t_minibatch)(indices_t)), []) #use itemgetter to access multiple element of a list (same as [l[u] for u in ind], use sum(list, []) to flatten the list\n",
    "        \n",
    "        kappa_pos, kappa_neg = model()\n",
    "        loss = loss_function(kappa_pos, kappa_neg, model.n_negative_interactions, t_minibatch, t_pos_minibatch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        history[\"epsilon\"].append(sigmoid(model.theta.item()) / 2)\n",
    "        history[\"loss\"].append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if epoch > early_stopping_kw[\"min_epochs\"]:\n",
    "            early_stopping(history[\"epsilon\"][-3], history[\"epsilon\"][-2], history[\"epsilon\"][-1], epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "            \n",
    "    t1 = time()\n",
    "    history[\"time\"] = t1 - t0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670d387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, edge_per_t = 100, 256, 4\n",
    "evidences_per_t = 4\n",
    "epsilon, mu, rho = 0.35, 0.1, 16\n",
    "\n",
    "X, edges, evidences = sod.simulate_BC(N, T, edge_per_t, evidences_per_t, (epsilon, mu, rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d380c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gradient_descent_BC_observe_positive(X, edges, rho, num_epochs = 100, epsilon0 = 0.25, \n",
    "                                               optimizer_name = \"adam\", lr = 0.05, seed = 222)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af214746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bc733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e50dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac0284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce486a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
