{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0567a6d9",
   "metadata": {},
   "source": [
    "# ML Estimation Noisy Observations Bounded Confidence Model\n",
    "In this notebook we estimate the parameter $\\epsilon$ in a BC model with noisy observations on the opinions.\n",
    "Instead of knowing $X$, we observe only $Y$, that is a Bernoulli sample of a sample of agents at each timestep.\n",
    "$Y_j = 1$ with probability $X_j$.\n",
    "\n",
    "The likelihood to be optimized is \n",
    "\n",
    "$\\mathcal{L}(\\epsilon) = \\sum\\limits_{j = 1,\\ldots,M} \\log ( s^j \\kappa_{\\epsilon} (e^j) + (1 - s^j) (1 - \\kappa_\\epsilon(e_t)) )$ $+\\sum\\limits_{j = 1,\\ldots,K} \\log \\left( y_j f_t(X_0)_j + (1 - y_j) (1 - f_t(X_0)_j) \\right)$,\n",
    "\n",
    "where $\\kappa = \\sigma(\\rho \\cdot (\\epsilon - | \\Delta X |))$ is the probability of having a positive interaction, and $s = 1$ if the interaction is positive, and $s = 0$ otherwise.\n",
    "\n",
    "$f_t(X_0)$ are the opinions of the agents at time $t$, given the initial opinion $X_0$.\n",
    "\n",
    "Hence, the loss is composed of two pieces, the neg-log-likelihood of the interactions (that depend on the estimates of the opinions), and the neg-log-likelihood of the opinions from the evidences (Y).\n",
    "\n",
    "We maximise $\\mathcal{L}$ with gradient descent.\n",
    "\n",
    "In this case, we estimate both $\\epsilon$ and $X_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ad5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "from simulator_opinion_dynamics import kappa_from_epsilon\n",
    "import simulator_opinion_dynamics as sod\n",
    "from initialize_model import EarlyStopping,RandomizeEpsilon,choose_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0753f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define a new function for setting up the optimizer, in order to have different learning rates for epsilon and X0\n",
    "def choose_optimizer_evidences(optimizer_name, lr, model, X0_lr_scale = 1):\n",
    "    optimizer_list = [\"adam\", \"SGD\", \"nadam\", \"adagrad\", \"RMSprop\"]\n",
    "    assert optimizer_name in optimizer_list, f\"Optimizer must be in {optimizer_list}\"\n",
    "    \n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr)\n",
    "        \n",
    "        optimizer = torch.optim.Adam([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr) #define the optimizer with the input learning rate\n",
    "    if optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr, momentum = 0.9) #define the optimizer with the input learning rate\n",
    "    if optimizer_name == \"nadam\":\n",
    "        optimizer = torch.optim.NAdam([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr) #define the optimizer with the input learning rate        \n",
    "    if optimizer_name == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr) #define the optimizer with the input learning rate\n",
    "    if optimizer_name == \"RMSprop\":\n",
    "        optimizer = torch.optim.RMSprop([\n",
    "            {'params': model.logit_X0, 'lr': lr * X0_lr_scale},\n",
    "            {'params': model.theta, 'lr': lr}\n",
    "        ], lr = lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "\n",
    "# function used for counting the repeated interactions at the same timestep\n",
    "def count_s_from_edge(e):\n",
    "    e_unique = e.unique(dim = 0, return_counts = True)\n",
    "    e_unique[0][:,2] = e_unique[0][:,2] * e_unique[1]\n",
    "    e_sum_s = e_unique[0]\n",
    "    return e_sum_s[e_sum_s[:,2] > 0]\n",
    "\n",
    "# define a sparse tensor to store the adj matrix for each timestep\n",
    "# this is useful to fast update the opinions at the varying of X0\n",
    "def edges_coo_mu(edges, mu, N):\n",
    "        edges_count_s = [count_s_from_edge(edges[t]) for t in range(len(edges))]\n",
    "        \n",
    "        M = [torch.sparse_coo_tensor(indices = edges_count_s[t][:,:2].T, dtype = torch.float32,\n",
    "                                     values = mu * edges_count_s[t][:,2], \n",
    "                                     size = [N, N]) for t in range(len(edges))]\n",
    "        \n",
    "        return M\n",
    "    \n",
    "# fast (deterministic) computation of the tensor X from edges and X0\n",
    "def X_from_X0_coo_edges(X0, M, T, N):\n",
    "    X = torch.zeros([T, N], dtype = torch.float32)\n",
    "    \n",
    "    X[0] = X0\n",
    "    for t in range(T - 1):\n",
    "        updates = ((X[t] * M[t].to_dense()).sum(dim = 1) - (X[t] * M[t].to_dense().T).sum(dim = 0) +\\\n",
    "                   (X[t] * M[t].to_dense().T).sum(dim = 1) - (X[t] * M[t].to_dense()).sum(dim = 0))\n",
    "        X[t+1] = X[t] + updates\n",
    "    \n",
    "    return X\n",
    "  \n",
    "# fast computation of diff_X and extraction of X of the nodes with observed evidences\n",
    "def evidences_diff_from_X0_coo_edges(X0, indices_M, values_M, T, N, edges, evidences_indices):\n",
    "    diff_X = torch.empty(T-1, len(edges[0]))\n",
    "    X_ = X0.clone().detach()\n",
    "    X_evidences = torch.empty(T, len(evidences_indices[0]))\n",
    "    \n",
    "    for t in range(T - 1):\n",
    "        diff_Xt = torch.sparse_coo_tensor(indices = indices_M[t],\n",
    "                                          values = values_M[t] * (X_[indices_M[t][0]] - X_[indices_M[t][1]]),\n",
    "                                          size = [N,N])\n",
    "        \n",
    "        updates = - torch.sparse.mm(diff_Xt, torch.ones(N,1))[:,0] + torch.sparse.mm(diff_Xt.T, torch.ones(N,1))[:,0]\n",
    "        \n",
    "        u,v,_ = edges[t].T\n",
    "        \n",
    "        diff_X[t] = X_[u] - X_[v]\n",
    "        X_evidences[t] = X_[evidences_indices[t]]\n",
    "        \n",
    "        X_ += updates\n",
    "    X_evidences[T-1] = X_[evidences_indices[T-1]]\n",
    "    \n",
    "    return diff_X, X_evidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07f1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BC_evidence_X_Estimation(nn.Module):\n",
    "    \n",
    "    def __init__(self, parameters0, X, edges, evidences):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        epsilon0, mu, rho = parameters0\n",
    "        self.rho = rho\n",
    "        self.mu = mu\n",
    "        \n",
    "        self.u,self.v,self.s,self.t = uvst = sod.convert_edges_uvst(edges)\n",
    "\n",
    "        self.X = X\n",
    "        self.diff_X = X[self.t,self.u] - X[self.t,self.v]\n",
    "        _, self.edge_per_t, _ = edges.size()\n",
    "        self.T, self.N = X.size()\n",
    "        \n",
    "        self.M = edges_coo_mu(edges, mu, self.N)\n",
    "                \n",
    "        self.evidences_per_t = len(evidences[0][0])\n",
    "\n",
    "        self.evidences_indices = torch.cat([evidences[k][0][None,:] for k in range(len(evidences))], dim = 0) #tensor with the indices of the users of which we know the evidence\n",
    "        self.evidences_opinions = torch.cat([evidences[k][1][None,:] for k in range(len(evidences))], dim = 0).reshape(self.T * self.evidences_per_t).to(torch.float32) #only the evidences of these users\n",
    "        self.evideneces = evidences\n",
    "        \n",
    "        X0 = torch.rand(self.N, dtype = torch.float32, requires_grad = True) # random initialization of the opinions\n",
    "        self.logit_X0 = nn.Parameter(torch.logit(X0))   #define the parameters of the model\n",
    "        \n",
    "        theta = torch.tensor([logit(2 * epsilon0)], requires_grad = True)\n",
    "        self.theta = nn.Parameter(theta)\n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        epsilon = torch.sigmoid(self.theta) / 2\n",
    "        X0 = torch.sigmoid(self.logit_X0)   #at each step clip X0 in the interval [0,1]\n",
    "        X = X_from_X0_coo_edges(X0, self.M, self.T, self.N)\n",
    "        \n",
    "        diff_X = X[self.t,self.u] - X[self.t, self.v] \n",
    "        kappa = kappa_from_epsilon(epsilon, diff_X, self.rho) # compute probability of interaction with current estimate of epsilon\n",
    "        \n",
    "        return X, kappa\n",
    "    \n",
    "    \n",
    "    def neg_log_likelihood_function(self, kappa, s, evidences_indices, evidences_opinions, evidences_per_t, X, t_minibatch):\n",
    "        T, _ = X.shape\n",
    "        real_opinions = torch.cat([X[t, evidences_indices[t]] for t in range(T)])\n",
    "        \n",
    "        loss_edges = -torch.sum(torch.log(s * kappa + (1 - s) * (1 - kappa)))\n",
    "        \n",
    "        # this steps avoid to obtain an estimate of X0 that is ~1-X0\n",
    "        # this can happen because the loss of the edges depends only on the distance between X, not on the abs values\n",
    "        loss_evidences = -torch.sum(torch.log(evidences_opinions * real_opinions + (1 - evidences_opinions) * (1 - real_opinions)))\n",
    "        loss_evidences_flip = -torch.sum(torch.log(evidences_opinions * (1 - real_opinions) + (1 - evidences_opinions) * (1 - (1 - real_opinions))))\n",
    "        \n",
    "        X0_flip = True if loss_evidences > loss_evidences_flip else False\n",
    "        \n",
    "        return torch.min(loss_edges + loss_evidences, loss_edges + loss_evidences_flip), X0_flip\n",
    "    \n",
    "    def neg_log_likelihood_function_minibatch(self, kappa, s, evidences_indices, evidences_opinions, evidences_per_t, X, t_minibatch):\n",
    "        T, _ = X.shape\n",
    "        real_opinions = torch.cat([X[t, evidences_indices[t]] for t in range(T)])\n",
    "        \n",
    "        loss_edges = -torch.sum(torch.log(s * kappa + (1 - s) * (1 - kappa))[t_minibatch])\n",
    "        \n",
    "        loss_evidences = -torch.sum(torch.log(evidences_opinions * real_opinions + (1 - evidences_opinions) * (1 - real_opinions))[t_minibatch])\n",
    "        loss_evidences_flip = -torch.sum(torch.log(evidences_opinions * (1 - real_opinions) + (1 - evidences_opinions) * (1 - (1 - real_opinions)))[t_minibatch])\n",
    "        \n",
    "        X0_flip = True if loss_evidences > loss_evidences_flip else False\n",
    "        \n",
    "        return torch.min(loss_edges + loss_evidences, loss_edges + loss_evidences_flip), X0_flip\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b607719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_BC_evidence_X(X, edges, evidences, mu, rho, num_epochs,\n",
    "                                   epsilon0 = 0.25, optimizer_name = \"adam\",\n",
    "                                   lr = 0.05,  X0_lr_scale = 1,\n",
    "                                   hide_progress = True, minibatch_size = 0, seed = None,\n",
    "                                   early_stopping_kw = {\"patience\": 20, \"min_delta\": 1e-5, \"min_epochs\": 20, \"long_run_delta\": 1e-5, \"long_run_diff\":10, \"long_run_patience\": 5}):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    u,v,s,t = uvst = sod.convert_edges_uvst(edges)\n",
    "    T,_ = X.shape\n",
    "    \n",
    "    \n",
    "    model_class = BC_evidence_X_Estimation\n",
    "    model = model_class((epsilon0, mu, rho), X, edges, evidences)\n",
    "    if minibatch_size == 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function\n",
    "    if minibatch_size > 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function_minibatch\n",
    "    \n",
    "    early_stopping = EarlyStopping(**early_stopping_kw)\n",
    "    \n",
    "    optimizer = choose_optimizer_evidences(optimizer_name, lr, model, X0_lr_scale)\n",
    "    \n",
    "    history = {\"epsilon\": [epsilon0], \"loss\": [], \"X0\": []}\n",
    "    \n",
    "    t0 = time()\n",
    "    for epoch in tqdm(range(num_epochs), disable = hide_progress):\n",
    "        t_minibatch = torch.randperm(T-1)[:minibatch_size]\n",
    "        \n",
    "        X_, kappa = model()\n",
    "        loss, X0_flip = loss_function(model, kappa, model.s, model.evidences_indices, model.evidences_opinions, \n",
    "                             model.evidences_per_t, X_, t_minibatch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        X0_estimate = sigmoid(model.logit_X0.detach()) + (1 - 2 * sigmoid(model.logit_X0.detach())) * X0_flip\n",
    "        history[\"X0\"].append(X0_estimate)\n",
    "        history[\"epsilon\"].append(sigmoid(model.theta.item()) / 2)\n",
    "        history[\"loss\"].append(loss.item())\n",
    "        \n",
    "        if loss.item() == np.inf:\n",
    "            \n",
    "            model = model_class((np.random.rand() / 2, mu, rho), X, edges, evidences)\n",
    "            optimizer = choose_optimizer_evidences(optimizer_name, lr, model, X0_lr_scale / 2)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if epoch > early_stopping_kw[\"min_epochs\"]:\n",
    "            \n",
    "            early_stopping(history[\"epsilon\"][-2], history[\"epsilon\"][-1], history[\"epsilon\"][-early_stopping_kw[\"long_run_diff\"]], epoch)\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "    \n",
    "    \n",
    "    t1 = time()\n",
    "    history[\"time\"] = t1 - t0\n",
    "    \n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941f9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, edge_per_t = 100, 256, 4\n",
    "evidences_per_t = 4\n",
    "epsilon, mu, rho = 0.35, 0.4, 16\n",
    "\n",
    "X, edges, evidences = sod.simulate_BC(N, T, edge_per_t, evidences_per_t, (epsilon, mu, rho), seed = 34945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cef59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gradient_descent_BC_evidence_X(X, edges, evidences, num_epochs = 200, \n",
    "                                         epsilon0 = 0.25, mu = mu, rho = rho, \n",
    "                                         optimizer_name = \"RMSprop\",\n",
    "                                         lr = 0.05, X0_lr_scale = 10, seed = 91368)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f637d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a451474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c910a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544ac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174aff94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
