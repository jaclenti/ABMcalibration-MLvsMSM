{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6839eb9f",
   "metadata": {},
   "source": [
    "# ML Estimation Full Observed Bounded Confidence Model\n",
    "In this notebook we estimate the parameter $\\epsilon$ in a BC model with full observations on edges and opinions.\n",
    "\n",
    "The likelihood to be optimized is \n",
    "\n",
    "$\\mathcal{L}(\\epsilon) = \\sum \\log (\\kappa \\cdot s + (1- \\kappa) \\cdot (1 - s) ) $,\n",
    "\n",
    "where $\\kappa = \\sigma(\\rho \\cdot (\\epsilon - | \\Delta X |))$ is the probability of having a positive interaction, and $s = 1$ if the interaction is positive, and $s = 0$ otherwise.\n",
    "\n",
    "We maximise $\\mathcal{L}$ with gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87da8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.special import expit as sigmoid\n",
    "from scipy.special import logit\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "from simulator_opinion_dynamics import kappa_from_epsilon\n",
    "import simulator_opinion_dynamics as sod\n",
    "from initialize_model import EarlyStopping,RandomizeEpsilon,choose_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2d8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_BC_Estimation(nn.Module):\n",
    "    \n",
    "    def __init__(self, parameters0, X, edges):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # epsilon0 is the initialization of epsilon\n",
    "        epsilon0, rho = parameters0\n",
    "        self.rho = rho\n",
    "        u,v,s,t = uvst = sod.convert_edges_uvst(edges)\n",
    "        # store the matrix of the differences of X and update it at each time\n",
    "        self.diff_X = X[t,u] - X[t,v]\n",
    "        # optimize theta, that is the logit of 2 * epsilon (this is useful to bound epsilon in [0, 0.5])\n",
    "        theta = torch.tensor([logit(2 * epsilon0)], requires_grad = True)\n",
    "        self.theta = nn.Parameter(theta)\n",
    "        \n",
    "    def forward(self):\n",
    "        epsilon = torch.sigmoid(self.theta) / 2\n",
    "        # at each step compute the probability of having positive interactions from the current epsilon\n",
    "        kappa = kappa_from_epsilon(epsilon, self.diff_X, self.rho)\n",
    "        return kappa\n",
    "    \n",
    "    def neg_log_likelihood_function(kappa, s, t_minibatch):\n",
    "        # compute the negative log likelihood, that is the loss to be optimized\n",
    "        return -(torch.sum(torch.log((kappa * s) + ((1 - kappa) * (1 - s)))))\n",
    "    \n",
    "    def neg_log_likelihood_function_minibatch(kappa, s, t_minibatch):\n",
    "        # same as before, when using minibatching\n",
    "        return -(torch.sum(torch.log((kappa * s) + ((1 - kappa) * (1 - s)))[t_minibatch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3950823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_simple_BC(X, edges, rho, num_epochs, epsilon0 = 0.25, optimizer_name = \"adam\",\n",
    "                               lr = 0.05, hide_progress = True, minibatch_size = 0, seed = None,\n",
    "                               early_stopping_kw = {\"patience\": 20, \"min_delta\": 1e-5, \n",
    "                                                    \"min_epochs\": 20, \"long_run_delta\": 1e-5, \n",
    "                                                    \"long_run_diff\":10, \"long_run_patience\": 5}):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    u,v,s,t = uvst = sod.convert_edges_uvst(edges)\n",
    "    \n",
    "    T,N = X.shape\n",
    "    \n",
    "    model_class = Simple_BC_Estimation\n",
    "    model = model_class((epsilon0, rho), X, edges)\n",
    "    if minibatch_size == 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function\n",
    "    if minibatch_size > 0:\n",
    "        loss_function = model_class.neg_log_likelihood_function_minibatch\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(**early_stopping_kw)\n",
    "    optimizer = choose_optimizer(optimizer_name, lr, model)\n",
    "    \n",
    "    # store all the estimates of epsilon and the loss at each epoch\n",
    "    history = {\"epsilon\": [epsilon0], \"loss\": []}\n",
    "    \n",
    "    t0 = time()\n",
    "    for epoch in tqdm(range(num_epochs), disable = hide_progress):\n",
    "        t_minibatch = torch.randperm(T-1)[:minibatch_size]\n",
    "        \n",
    "        kappa = model()\n",
    "        loss = loss_function(kappa, s, t_minibatch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        history[\"epsilon\"].append(sigmoid(model.theta.item()) / 2)\n",
    "        history[\"loss\"].append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if epoch > early_stopping_kw[\"min_epochs\"]:\n",
    "            early_stopping(history[\"epsilon\"][-3], history[\"epsilon\"][-2], history[\"epsilon\"][-1], epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "            \n",
    "    t1 = time()\n",
    "    history[\"time\"] = t1 - t0\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932e3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, edge_per_t = 100, 256, 4\n",
    "evidences_per_t = 4\n",
    "epsilon, mu, rho = 0.12, 0.4, 16\n",
    "\n",
    "X, edges, evidences = sod.simulate_BC(N, T, edge_per_t, evidences_per_t, (epsilon, mu, rho), seed = 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c53254",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gradient_descent_simple_BC(X, edges, rho, num_epochs = 100, epsilon0 = 0.25, optimizer_name = \"adam\",\n",
    "                           lr = 0.05, seed = 2912)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db7107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dfdefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc7f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d0eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
